# Automated Segmentation and Registration for Eustachian Tube Disfunction
Aiming to develop state-of-art deep learning model for semantic segmentation of Eustachian tube CT scans with the use of supervised model - nnU-net - and unsupervised models - VoxelMorph and DeepReg.

## Step 0: Fork this GitHub repository 
```
git clone https://github.com/mikami520/CIS2-EustachianTube.git
```

## Step 1: Set up two environments using .yml files in environments/ (virtual environment is recommended)
To Do:


## Step 2: Preprocess datasets
### Step 2.1: Register data to template
Activate scripting environment
```
cd <path to repo>/preprocessing
```
Register data to template (can be used for multiple segmentations propagation)
```
python3 registration.py <full path of base dir> <relative path to nifti images dir> <relative path to segmentations dir> 
```
If you want to make sure correspondence of the name and value of segmentations, you can add the following commands after above command
```
LabelName1 LabelValue1 LabelName2 LabelValue2 LabelName3 LabelValue3 ...
```
For example, if I have two labels for maxillary sinus named L-MS and R-MS
```
python3 registration.py /Users/mikamixiao/Desktop images labels L-MS 1 R-MS 2
```
Final output of registered images and segmentations will be saved in 
```
imagesRS/ && labelsRS/
```
### Step 2.2: Create datasplit for training/testing. Validation will be chosen automatically by nnUNet (filename format should be taskname_xxx.nii.gz)
```
python3 split_data.py -bp <full path of base dir> -ip <relative path to nifti images dir (imagesRS)> -sp <relative path to nifti segmentations dir (labelsRS)> -sl <a list of label name and corresponding label value> -ti <task id for nnUNet preprocessing> -tn <name of task>
```
For example
```
python3 split_data.py -bp /Users/mikamixiao/Desktop -ip imagesRS -sp labelsRS -sl 1 L-MS 2 R-MS -ti 001 -tn Sinus
```

## Step 3: Setup bashrc

Edit your `~/.bashrc` file with `gedit ~/.bashrc` or `nano ~/.bashrc`. At the end of the file, add the following lines:

```
export nnUNet_raw_data_base="<ABSOLUTE PATH TO BASE_DIR>/nnUnet/nnUNet_raw_data_base" 
export nnUNet_preprocessed="<ABSOLUTE PATH TO BASE_DIR>/nnUNet_preprocessed" 
export RESULTS_FOLDER="<ABSOLUTE PATH TO BASE_DIR>/nnUnet/nnUNet_trained_models"
```

After updating this you will need to source your `~/.bashrc` file.

```
source ~/.bashrc
```

This will deactivate your current conda environment.

## Step 4: Verify and preprocess data
Activate nnUNet environment
```
source <virtual environment folder name>/bin/activate
```
Run nnUNet preprocessing script.
```
nnUNet_plan_and_preprocess -t <task_id> --verify_dataset_integrity
```
Potential Error: You may need to edit the dataset.json file so that the labels are sequential. If you have at least 10 labels, then labels `10, 11, 12,...` will be arranged before labels `2, 3, 4, ...`. Doing this in a text editor is completely fine!

## Step 5: Begin Training

```
nnUNet_train 3d_fullres nnUNetTrainerV2 Task<task_num>_TemporalBone Y --npz
```

`Y` refers to the number of folds for cross-validation. If `Y` is set to `all` then all of the data will be used for training. If you want to try 5-folds cross validation, you should define Y as `0, 1, 2, 3, 4 ` for five times.

`--npz` makes the models save the softmax outputs (uncompressed, large files) during the final validation. It should only be used if you are training multiple configurations, which requires `nnUNet_find_best_configuration` to find the best model. We omit this by default.

## Step 6: Run inference

`nnUNet_find_best_configuration` will print a string to the terminal with the inference commands you need to use.
The easiest way to run inference is to simply use these commands.

If you wish to manually specify the configuration(s) used for inference, use the following commands:

For each of the desired configurations, run:

```
nnUNet_predict -i INPUT_FOLDER -o OUTPUT_FOLDER -t TASK_NAME_OR_ID -m CONFIGURATION --save_npz
```

Only specify `--save_npz` if you intend to use ensembling. `--save_npz` will make the command save the softmax
probabilities alongside of the predicted segmentation masks requiring a lot of disk space.

Please select a separate `OUTPUT_FOLDER` for each configuration!

If you wish to run ensembling, you can ensemble the predictions from several configurations with the following command:

```bash
nnUNet_ensemble -f FOLDER1 FOLDER2 ... -o OUTPUT_FOLDER -pp POSTPROCESSING_FILE
```

You can specify an arbitrary number of folders, but remember that each folder needs to contain npz files that were
generated by `nnUNet_predict`. For ensembling you can also specify a file that tells the command how to postprocess.
These files are created when running `nnUNet_find_best_configuration` and are located in the respective trained model directory `(RESULTS_FOLDER/nnUNet/CONFIGURATION/TaskXXX_MYTASK/TRAINER_CLASS_NAME__PLANS_FILE_IDENTIFIER/postprocessing.json or RESULTS_FOLDER/nnUNet/ensembles/TaskXXX_MYTASK/ensemble_X__Y__Z--X__Y__Z/postprocessing.json)`. You can also choose to not provide a file (simply omit -pp) and nnU-Net will not run postprocessing.

Note that per default, inference will be done with all available folds. We very strongly recommend you use all 5 folds.
Thus, all 5 folds must have been trained prior to running inference. The list of available folds nnU-Net found will be
printed at the start of the inference.

## Step 7: Evaluate inference
To compute the dice score and average hausdorff distance:
```
cd <path to repo>/metrics
```
Run the metrics.py to output a CSV file that contain the dice score and hausdorff distance for each segmentation:
```
python3 metrics.py -bp <full path of base dir> -gp <relative path of ground truth dir> -pp <relative path of predicted segmentations dir> -sp <save dir>
```
